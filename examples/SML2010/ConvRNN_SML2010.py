# https://github.com/KurochkinAlexey/ConvRNN
import os
os.chdir(os.path.abspath(os.path.dirname(__file__)))
import torch
from torch import nn
from torch.utils.data import TensorDataset, DataLoader
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

#data1 = pd.read_csv("examples/NEW-DATA-1.T15.txt", sep=' ')
#data2 = pd.read_csv("examples/NEW-DATA-2.T15.txt", sep=' ')
data1 = pd.read_csv("NEW-DATA-1.T15.txt", sep=' ')
data2 = pd.read_csv("NEW-DATA-2.T15.txt", sep=' ')
target = '3:Temperature_Comedor_Sensor'
cols = [
    '3:Temperature_Comedor_Sensor',
    '4:Temperature_Habitacion_Sensor',
    '5:Weather_Temperature',
    '6:CO2_Comedor_Sensor',
    '7:CO2_Habitacion_Sensor',
    '8:Humedad_Comedor_Sensor',
    '9:Humedad_Habitacion_Sensor',
    '10:Lighting_Comedor_Sensor',
    '11:Lighting_Habitacion_Sensor',
    '12:Precipitacion',
    '13:Meteo_Exterior_Crepusculo',
    '14:Meteo_Exterior_Viento',
    '15:Meteo_Exterior_Sol_Oest',
    '16:Meteo_Exterior_Sol_Est',
    '20:Exterior_Entalpic_2',
    '21:Exterior_Entalpic_turbo',
    '22:Temperature_Exterior_Sensor']
data1.head()
train_size = 3200
val_size = 400
depth = 90
batch_size = 128
prediction_horizon = 7

X_train1 = np.zeros((len(data1), depth, len(cols)))
y_train1 = np.zeros((len(data1), 1))

for i, name in enumerate(cols):
    for j in range(depth):
        X_train1[:, j, i] = data1[name].shift(depth - j - 1).fillna(method="bfill")
y_train1 = data1[target].shift(-prediction_horizon).fillna(method='ffill')

X_train1 = X_train1[depth:-prediction_horizon]
y_train1 = y_train1[depth:-prediction_horizon]

X2 = np.zeros((len(data2), depth, len(cols)))
y2 = np.zeros((len(data2), 1))

for i, name in enumerate(cols):
    for j in range(depth):
        X2[:, j, i] = data2[name].shift(depth - j - 1).fillna(method="bfill")
y2 = data2[target].shift(-prediction_horizon).fillna(method='ffill')

X_train2 = X2[:train_size - len(data1)]
y_train2 = y2[:train_size - len(data1)]

X_val = X2[train_size - len(data1):train_size - len(data1) + val_size]
y_val = y2[train_size - len(data1):train_size - len(data1) + val_size]

X_test = X2[train_size - len(data1) + val_size:]
y_test = y2[train_size - len(data1) + val_size:]

X_train2 = X_train2[depth:]
y_train2 = y_train2[depth:]
X_train = np.concatenate([X_train1, X_train2], axis=0)
y_train = np.concatenate([y_train1, y_train2], axis=0)
X_train.shape, y_train.shape

X_train_min, y_train_min = X_train.min(axis=0), y_train.min(axis=0)
X_train_max, y_train_max = X_train.max(axis=0), y_train.max(axis=0)

X_train = (X_train - X_train_min) / (X_train_max - X_train_min + 1e-9)
X_val = (X_val - X_train_min) / (X_train_max - X_train_min + 1e-9)
X_test = (X_test - X_train_min) / (X_train_max - X_train_min + 1e-9)

y_train = (y_train - y_train_min) / (y_train_max - y_train_min + 1e-9)
y_val = (y_val - y_train_min) / (y_train_max - y_train_min + 1e-9)
y_test = (y_test - y_train_min) / (y_train_max - y_train_min + 1e-9)

X_train_t = torch.Tensor(X_train)
X_val_t = torch.Tensor(X_val)
X_test_t = torch.Tensor(X_test)
y_train_t = torch.Tensor(y_train)
y_val_t = torch.Tensor(y_val.values)
y_test_t = torch.Tensor(y_test.values)

train_loader = DataLoader(TensorDataset(X_train_t, y_train_t), shuffle=True, batch_size=batch_size)
val_loader = DataLoader(TensorDataset(X_val_t, y_val_t), shuffle=False, batch_size=batch_size)
test_loader = DataLoader(TensorDataset(X_test_t, y_test_t), shuffle=False, batch_size=batch_size)


class ConvRNN(nn.Module):
    def __init__(self, input_dim, timesteps, output_dim, kernel_size1=7, kernel_size2=5, kernel_size3=3,
                 n_channels1=32, n_channels2=32, n_channels3=32, n_units1=32, n_units2=32, n_units3=32):
        super().__init__()
        self.avg_pool1 = nn.AvgPool1d(2, 2)
        self.avg_pool2 = nn.AvgPool1d(4, 4)
        self.conv11 = nn.Conv1d(input_dim, n_channels1, kernel_size=kernel_size1)
        self.conv12 = nn.Conv1d(n_channels1, n_channels1, kernel_size=kernel_size1)
        self.conv21 = nn.Conv1d(input_dim, n_channels2, kernel_size=kernel_size2)
        self.conv22 = nn.Conv1d(n_channels2, n_channels2, kernel_size=kernel_size2)
        self.conv31 = nn.Conv1d(input_dim, n_channels3, kernel_size=kernel_size3)
        self.conv32 = nn.Conv1d(n_channels3, n_channels3, kernel_size=kernel_size3)
        self.gru1 = nn.GRU(n_channels1, n_units1, batch_first=True)
        self.gru2 = nn.GRU(n_channels2, n_units2, batch_first=True)
        self.gru3 = nn.GRU(n_channels3, n_units3, batch_first=True)
        self.linear1 = nn.Linear(n_units1 + n_units2 + n_units3, output_dim)
        self.linear2 = nn.Linear(input_dim * timesteps, output_dim)
        self.zp11 = nn.ConstantPad1d(((kernel_size1 - 1), 0), 0)
        self.zp12 = nn.ConstantPad1d(((kernel_size1 - 1), 0), 0)
        self.zp21 = nn.ConstantPad1d(((kernel_size2 - 1), 0), 0)
        self.zp22 = nn.ConstantPad1d(((kernel_size2 - 1), 0), 0)
        self.zp31 = nn.ConstantPad1d(((kernel_size3 - 1), 0), 0)
        self.zp32 = nn.ConstantPad1d(((kernel_size3 - 1), 0), 0)

    def forward(self, x):
        x = x.permute(0, 2, 1)
        # line1
        y1 = self.zp11(x)
        y1 = torch.relu(self.conv11(y1))
        y1 = self.zp12(y1)
        y1 = torch.relu(self.conv12(y1))
        y1 = y1.permute(0, 2, 1)
        out, h1 = self.gru1(y1)
        # line2
        y2 = self.avg_pool1(x)
        y2 = self.zp21(y2)
        y2 = torch.relu(self.conv21(y2))
        y2 = self.zp22(y2)
        y2 = torch.relu(self.conv22(y2))
        y2 = y2.permute(0, 2, 1)
        out, h2 = self.gru2(y2)
        # line3
        y3 = self.avg_pool2(x)
        y3 = self.zp31(y3)
        y3 = torch.relu(self.conv31(y3))
        y3 = self.zp32(y3)
        y3 = torch.relu(self.conv32(y3))
        y3 = y3.permute(0, 2, 1)
        out, h3 = self.gru3(y3)
        h = torch.cat([h1[-1], h2[-1], h3[-1]], dim=1)
        out1 = self.linear1(h)
        out2 = self.linear2(x.contiguous().view(x.shape[0], -1))
        out = out1 + out2
        return out


model = ConvRNN(X_train.shape[2], X_train.shape[1], 1, n_channels1=128, n_channels2=128, n_channels3=128,
                n_units1=128, n_units2=128, n_units3=128)
opt = torch.optim.Adam(model.parameters(), lr=0.001)

epoch_scheduler = torch.optim.lr_scheduler.StepLR(opt, 20, gamma=0.9)

from sklearn.metrics import mean_squared_error, mean_absolute_error
import time


fig, ax = plt.subplots(figsize=(6,3))
plt.ion()
epochs = 1000
loss = nn.MSELoss()
patience = 75
min_val_loss = 9999
counter = 0
for i in range(epochs):
    mse_train = 0
    iteration_start = time.monotonic()
    for batch_x, batch_y in train_loader:
        batch_x = batch_x
        batch_y = batch_y
        opt.zero_grad()
        y_pred = model(batch_x)
        y_pred = y_pred.squeeze(1)
        l = loss(y_pred, batch_y)
        l.backward()
        mse_train += l.item() * batch_x.shape[0]
        opt.step()
    epoch_scheduler.step()
    with torch.no_grad():
        mse_val = 0
        preds = []
        true = []
        for batch_x, batch_y in val_loader:
            batch_x = batch_x
            batch_y = batch_y
            output = model(batch_x)
            output = output.squeeze(1)
            preds.append(output.detach().cpu().numpy())
            true.append(batch_y.detach().cpu().numpy())
            mse_val += loss(output, batch_y).item() * batch_x.shape[0]
    preds = np.concatenate(preds)
    true = np.concatenate(true)

    if min_val_loss > mse_val ** 0.5:
        min_val_loss = mse_val ** 0.5
        print("Saving...")
        torch.save(model.state_dict(), "convrnn_sml2010.pt")
        counter = 0
    else:
        counter += 1

    if counter == patience:
        break
    print("Iter: ", i, "train: ", (mse_train / len(X_train_t)) ** 0.5, "val: ", (mse_val / len(X_val_t)) ** 0.5)
    iteration_end = time.monotonic()
    print("Iter time: ", iteration_end - iteration_start)
    if (i % 1 == 0):
        preds = preds * (y_train_max - y_train_min) + y_train_min
        true = true * (y_train_max - y_train_min) + y_train_min
        mse = mean_squared_error(true, preds)
        mae = mean_absolute_error(true, preds)
        print("mse: ", mse, "mae: ", mae)
        #plt.figure(figsize=(20, 10))
        plt.cla()
        ax.plot(preds)
        ax.plot(true)
        #plt.show()
        plt.pause(.2)
